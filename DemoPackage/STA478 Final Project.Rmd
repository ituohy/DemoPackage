---
title: "STA478 Final Project"
author: "Ian Tuohy"
date: "2023-12-10"
output:
  pdf_document: default
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(glmnet)
library(caret)
library(tidyverse)
library(ModelMetrics)
library(stats)
library(tree)
```

```{r, include=FALSE}
############# RUN OF CODE TO BE ABLE TO CALL OBJECTS TO EMBED #################

# Set seed for repeatability
set.seed(2023)

# Load in data
bank <- read.csv("bankloan.csv")

# Remove ID Column
bank <- subset(bank, select = -c(ID, Experience))

# Clean data types
bank$CreditCard <- as.factor(bank$CreditCard)
bank$Online <- as.factor(bank$Online)
bank$CD.Account <- as.factor(bank$CD.Account)
bank$Securities.Account <- as.factor(bank$Securities.Account)
bank$Personal.Loan <- as.factor(bank$Personal.Loan)
bank$Education <- as.factor(bank$Education)
bank$Family <- as.factor(bank$Family)

# Create test and validation sets of data, using an 80/20 split.
test_fraction <- 0.2
random_subset <- sample.int(nrow(bank),
                            nrow(bank)*test_fraction) 
bank.train <- bank[-random_subset,]
bank.test <- bank[random_subset,]

# ENET model setup
x <- model.matrix(Personal.Loan~.-ZIP.Code, data=bank.train)[,-1]
y <- bank.train$Personal.Loan

# Original model
cv.ENET <- cv.glmnet(x, y, alpha=0.7, family="binomial")

# Determine best lambda value, create new model
ENET.mod <- glmnet(x, y, alpha=0.7, lambda=cv.ENET$lambda.min, family="binomial")

# Create predictions for model on unseen data, assign as 0 or 1.
probs <- predict(ENET.mod, newx=model.matrix(Personal.Loan~.-ZIP.Code, data=bank.test)[,-1])
ENET_Confusion_Matrix <- ifelse(probs<0.5, 0, 1)

# Original tree model
tree.fit <- tree(Personal.Loan~.-ZIP.Code, bank, subset=random_subset)

# Cross validation to prune tree
tree.fit.cv <- cv.tree(tree.fit, FUN = prune.misclass)

# Create new model with optimal number of leaves
tree.fit.cv.best <-  prune.misclass(tree.fit, best=tree.fit.cv$size[which.min(tree.fit.cv$dev)])

# Create confusion matrix for tree model
Tree_Confusion_Matrix <- predict(tree.fit.cv.best, bank.test, type="class")

```

**Intro**

The topic that I decided to study for this analysis was personal loan approvals, utilizing bank data to predict whether or not a person should be approved for a loan. This prediction is based of multiple different predictors, such as someone’s loan history, income, and current debt amounts. I chose this topic because I think that one of the prime applications for data and modeling is in finance as a whole, and utilizing data in order to evaluate someone’s loan approval is a very realistic model I may see in the future. The data comes from kaggle, and is 5000 observations of a total of 13 predictors, with 1 response variable. I've included the head of the dataset, which shows the first 6 observations and their resulting columns.

```{r}
head(bank)
```

**Data Eval**

In order to clean my data, I had to change a few of the variable types, such as from numeric to factors, as well as keeping an eye out for any unwanted or null values. Luckily, the data came from kaggle mostly cleaned, and the most that I had to do was remove ID and Experience and split the dataset into a validation and training set. I removed ID because it was redundant to normal numbering, and I removed experience, as there wasn't much explanation given by the dataset creator as to what that was. To further explain my variables they are as follows. Age is the age of the customer. Income is the customer income. Zip.Code is the customer's zip code of their given address. Family is their number of family members. CCAvg is their credit card average score. Education is the customer's education, with 1 being high school and 2 and 3 being subsequent degrees acquired, with 2 being a bachelors and 3 being a master's. Mortgage is their mortgage amount, in thousands. And our response variable, Personal.Loan, details whether or not the person was approved, with 0 meaning that the person was denied, and 1 meaning they were approved.

```{r}
names(bank)
```

**Modeling Intro**

I chose to utilize decision trees and Elastic Net modeling. Both were implemented with R, with the decision trees being implemented with the “tree” package” and the ENET modeling being implemented with the “glmnet” package. The alpha level I chose for ENET was 0.7. Further, when I implemented my models, I utilized a 80/20 cross validation split of the data, with 4000 observations in my training dataset and 1000 observations in my validation dataset. With the two models that I chose, there are a few different limitations. For Elastic Net, it comes with a high degree of complexity, that is, it is hard to interpret how the model comes to a result given inputs. On the other hand, my tree is also limited, cross validation left my tree with only 6 leaves, leaving not many different choices being made during the modeling process. The following figure is the result of cross validating my decision tree, showing that 6 was the best final choice.

```{r}
plot(tree.fit.cv$size, tree.fit.cv$dev, type = "b")
```

**Analysis Results**

As stated above, I chose an 80/20 split of my data for cross validation purposes. I chose this because I had a relatively large dataset of 5000 observations, so I felt confident that using a random split instead of k-fold cross validation would be sufficient. During my analysis of each of my models, I found that the tree model was more accurate than the Elastic Net model, given that it only gave 13 incorrect predictions of the unseen data, compared to the 42 incorrect predictions given by the ENET model. The following is the Confusion Matrix of each model, which shows the amount of correct predictions for each model, as well as how the models lacked in prediction.

```{r}
table(Tree_Confusion_Matrix, bank.test$Personal.Loan)
table(ENET_Confusion_Matrix, bank.test$Personal.Loan)
```

**Discussion of Final Models and Analysis**

My final models that I settled on were a single decision tree with 6 leaves, as well as an Elastic Net model utilizing shrinkage. Both models used almost every variable from the original dataset, minus Zip Code. ID was also taken out during the data cleaning process. My explainable model, the decision tree, utilizes only five choices, and only 4 different variables. The process of choices is as follows: Income > 94.5, Education == 1, Family == 1 or 2, Income > 117, and CCAvg. It can be inference that Income is the most important variable in predicting whether a personal loan is approved or not, given that it was the first choice in the final tree. I've included my final decision tree below, after cross validation took place.

```{r}
plot(tree.fit.cv.best)
text(tree.fit.cv.best, pretty = 1)
```

**Conclusions**

In conclusion, I learned that both finding a dataset that is easy to work with and that seems to be interesting is a difficult task. When originally assigned, I probably went through 20 or so different datasets finding what I wanted to work with, and nothing jumped out at me. When I found this dataset, I was really intrigued at the sheer amount of variables that could go into predicting a personal loan application. On the modeling side, I also learned that I have much more to learn when it comes choosing a model to stick with. That being said, it was very interesting choosing what model I wanted to use, as I feel like I have so many under my belt after this past semester. In the future, I’d like to leave myself more time to figure out exactly what model would work best for the dataset I’m using. I ended up with a very successful model, with a low error rate on unseen data, but it’s possible I still chose the wrong model. Further, I’d also like to figure out a better way to explain a decision tree. It was my first time utilizing it, especially as my “explainable” model, and I don’t think I got across my explanation as well as I’d like.

**Citations**

Dataset found at https://www.kaggle.com/datasets/vikramamin/bank-loan-approval-lr-dt-rf-and-auc

**Appendix**

```{r}
# Set seed for repeatability
set.seed(2023)

# Load in data
bank <- read.csv("bankloan.csv")

# Remove ID Column
bank <- subset(bank, select = -c(ID, Experience))

# Clean data types
bank$CreditCard <- as.factor(bank$CreditCard)
bank$Online <- as.factor(bank$Online)
bank$CD.Account <- as.factor(bank$CD.Account)
bank$Securities.Account <- as.factor(bank$Securities.Account)
bank$Personal.Loan <- as.factor(bank$Personal.Loan)
bank$Education <- as.factor(bank$Education)
bank$Family <- as.factor(bank$Family)

# Create test and validation sets of data, using an 80/20 split.
test_fraction <- 0.2
random_subset <- sample.int(nrow(bank),
                            nrow(bank)*test_fraction) 
bank.train <- bank[-random_subset,]
bank.test <- bank[random_subset,]

# ENET model setup
x <- model.matrix(Personal.Loan~.-ZIP.Code, data=bank.train)[,-1]
y <- bank.train$Personal.Loan

# Original model
cv.ENET <- cv.glmnet(x, y, alpha=0.7, family="binomial")

# Determine best lambda value, create new model
ENET.mod <- glmnet(x, y, alpha=0.7, lambda=cv.ENET$lambda.min, family="binomial")

# Create predictions for model on unseen data, assign as 0 or 1.
probs <- predict(ENET.mod, newx=model.matrix(Personal.Loan~.-ZIP.Code, data=bank.test)[,-1])
ENET_Confusion_Matrix <- ifelse(probs<0.5, 0, 1)

# Original tree model
tree.fit <- tree(Personal.Loan~.-ZIP.Code, bank, subset=random_subset)

# Cross validation to prune tree
tree.fit.cv <- cv.tree(tree.fit, FUN = prune.misclass)

# Create new model with optimal number of leaves
tree.fit.cv.best <-  prune.misclass(tree.fit, best=tree.fit.cv$size[which.min(tree.fit.cv$dev)])

# Create confusion matrix for tree model
Tree_Confusion_Matrix <- predict(tree.fit.cv.best, bank.test, type="class")

save(bank, bank.test, bank.train, file="final_project.RData")

load(file="final_project.RData")

```